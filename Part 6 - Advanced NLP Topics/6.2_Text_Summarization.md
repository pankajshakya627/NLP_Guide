# Text Summarization

Text summarization is the task of automatically generating a short summary of a longer text. This can be useful for quickly getting the gist of a long article or document.

There are two main approaches to text summarization:

1.  **Extractive summarization:** This approach works by identifying and extracting the most important sentences from the original text and combining them to form a summary.
2.  **Abstractive summarization:** This approach works by generating new sentences and phrases to create a summary.

## Extractive Summarization

Extractive summarization is the simpler of the two approaches. It works by scoring each sentence in the text and then selecting the sentences with the highest scores to be included in the summary.

### Python Example

This example shows how to use the `sumy` library to perform extractive summarization on a piece of text.

```python
# You may need to install this library
# pip install sumy
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer

text = "Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation."

# Create a parser
parser = PlaintextParser.from_string(text, Tokenizer("english"))

# Create a summarizer
summarizer = LsaSummarizer()

# Summarize the text
summary = summarizer(parser.document, 2)  # Summarize to 2 sentences

for sentence in summary:
    print(sentence)
```

**Output:**
```
Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages.
Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.
```

## Abstractive Summarization

Abstractive summarization is a more complex approach to text summarization. It works by generating new sentences and phrases to create a summary.

Abstractive summarization models are typically based on deep learning, and they are trained on large datasets of text and summaries.

### Python Example

Below are implementations showing how to use the Hugging Face Transformers library for text summarization. We show the high-level `pipeline` API, and then specific examples for loading models in **TensorFlow** and **PyTorch**.

#### Option 1: High-Level Pipeline (Framework Agnostic)

```python
from transformers import pipeline

# Load the summarization pipeline
summarizer = pipeline("summarization")

text = "Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation."

# Summarize the text
summary = summarizer(text, max_length=50, min_length=25, do_sample=False)

print(summary[0]['summary_text'])
```

#### Option 2: TensorFlow/Keras Specific Loading

```python
from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer
import tensorflow as tf

model_name = "t5-small"

# Load Tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load Model (TensorFlow version)
model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)

text = "Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation."

# Prepare Input
# T5 uses a prefix for specific tasks
inputs = tokenizer("summarize: " + text, return_tensors="tf", max_length=512, truncation=True)

# Inference
outputs = model.generate(inputs["input_ids"], max_length=50, min_length=25, do_sample=False)
decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(decoded_output)
```

#### Option 3: PyTorch Specific Loading

```python
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import torch

model_name = "t5-small"

# Load Tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load Model (PyTorch version)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

text = "Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation."

# Prepare Input
# T5 uses a prefix for specific tasks
inputs = tokenizer("summarize: " + text, return_tensors="pt", max_length=512, truncation=True)

# Inference
with torch.no_grad():
    outputs = model.generate(inputs["input_ids"], max_length=50, min_length=25, do_sample=False)
    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(decoded_output)
```
**Output:**
```
Natural Language Processing is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages . NLP is related to the area of human-computer interaction .
```
