# Topic Modeling

Topic modeling is an unsupervised machine learning technique that is used to discover the abstract "topics" that occur in a collection of documents.

Topic modeling is a powerful tool for understanding large collections of text data. It can be used to identify the main themes in a corpus of documents, to track the evolution of topics over time, and to find documents that are relevant to a particular topic.

## Latent Dirichlet Allocation (LDA)

Latent Dirichlet Allocation (LDA) is a popular topic modeling algorithm. It is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar.

### Mathematical Derivation

The LDA model assumes that each document is a mixture of a small number of topics, and that each word in the document is attributable to one of the document's topics.

The generative process for LDA is as follows:

1.  For each document, choose a distribution over topics.
2.  For each word in the document, choose a topic from the distribution over topics.
3.  Choose a word from the chosen topic.

The goal of LDA is to infer the hidden topic structure from the observed documents.

### Python Example

This example shows how to use the Gensim library to perform topic modeling on a piece of text.

```python
from gensim.corpora import Dictionary
from gensim.models import LdaModel
from nltk.tokenize import word_tokenize

# Sample corpus
corpus = [
    "this is a sentence about cats",
    "this is a sentence about dogs",
    "cats and dogs are pets",
    "i like my pet cat",
    "i like my pet dog"
]

# Tokenize the corpus
tokenized_corpus = [word_tokenize(doc) for doc in corpus]

# Create a dictionary
dictionary = Dictionary(tokenized_corpus)

# Create a bag-of-words corpus
bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]

# Train an LDA model
lda_model = LdaModel(bow_corpus, num_topics=2, id2word=dictionary)

# Print the topics
for topic in lda_model.print_topics():
    print(topic)
```

**Output:**
```
(0, '0.088*"pet" + 0.088*"like" + 0.088*"my" + 0.088*"dog" + 0.087*"i" + 0.025*"is" + 0.025*"this" + 0.025*"sentence" + 0.025*"a" + 0.025*"about"')
(1, '0.095*"is" + 0.095*"a" + 0.095*"sentence" + 0.095*"about" + 0.095*"this" + 0.065*"cats" + 0.035*"and" + 0.035*"dogs" + 0.035*"are" + 0.035*"pets"')
```

The output shows the two topics that were discovered by the LDA model. The first topic is about dogs, and the second topic is about cats.
